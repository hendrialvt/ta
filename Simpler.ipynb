{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, shutil, math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from hilbert import decode\n",
    "from PIL import Image\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, classification_report\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from skimage.transform import resize\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open The Main Data Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MainFolder = \"MixedData\"\n",
    "FileListMain = os.listdir(MainFolder)\n",
    "\n",
    "evaluateLr = False # Toogle to plot learning rate per epoch curve (use only if needed)\n",
    "useColormap = True # Toogle to use colormapping\n",
    "\n",
    "# Lists of transformation methods available\n",
    "transformMethod = ['Normal', 'Upscale', 'Descale']\n",
    "BgMethod = ['Normal', 'NonZero']\n",
    "RawMethod = ['Normal', 'Normalized']\n",
    "ModelMethod = ['ANN', 'CNN']\n",
    "# Amount of folds for k-fold cross validation\n",
    "foldAmount = 5\n",
    "\n",
    "# Size of training data for train/val split\n",
    "splitSize = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories or folder for datasaving purpose\n",
    "currentDirectory = os.getcwd()\n",
    "# Main Folder\n",
    "Gambar = os.path.join(currentDirectory, 'Gambar')\n",
    "# Folder to save raw plot data\n",
    "rawPlotPath = os.path.join(Gambar, 'RawPlot')\n",
    "# Folder to save normalized raw data\n",
    "normalizedRawPath = os.path.join(Gambar, 'NormalizedRaw')\n",
    "# Folder to save background data\n",
    "backgroundPath = os.path.join(Gambar, 'Background')\n",
    "# Folder to save removed background data\n",
    "removedBackgroundPath = os.path.join(Gambar, 'RemovedBackground')\n",
    "# Folder to save removed Background data non zero normalized\n",
    "removedBackgroundPathNonZero = os.path.join(Gambar, 'RemovedBackgroundNonZero')\n",
    "# Folder to save transformed and colormapped data\n",
    "transformedPath = os.path.join(Gambar, 'TransformedData')\n",
    "# Folder to save learning curve graph\n",
    "evaluatePath = os.path.join(Gambar, 'Evaluate')\n",
    "# Folder to save best model for each transformation-colormapping combination\n",
    "modelSavePath = os.path.join(Gambar, 'ModelSave')\n",
    "# Create the Folders\n",
    "allPaths = [Gambar,\n",
    "            rawPlotPath,\n",
    "            normalizedRawPath,\n",
    "            backgroundPath,\n",
    "            removedBackgroundPath,\n",
    "            removedBackgroundPathNonZero,\n",
    "            transformedPath,\n",
    "            evaluatePath,\n",
    "            modelSavePath]\n",
    "for path in allPaths:\n",
    "    if os.path.isdir(path):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a tokenizer for a data\n",
    "def tokenize_labels(labels):\n",
    "    # Instantiate the Tokenizer class\n",
    "    label_tokenizer = Tokenizer(oov_token='<OOV>', lower=False)\n",
    "    # Fit the tokenizer to the labels\n",
    "    label_tokenizer.fit_on_texts(labels)\n",
    "    # Save the word index\n",
    "    label_word_index = label_tokenizer.word_index\n",
    "    return label_word_index, label_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<OOV>': 1, 'BckGnd': 2, 'Co': 3, 'Cs': 4, 'Eu': 5}\n"
     ]
    }
   ],
   "source": [
    "# Create a tokenizer for the radionuclide part of data\n",
    "radioLabel = []\n",
    "for fileName in FileListMain:\n",
    "    nameSplit = fileName.split(\"-\")\n",
    "    radioLabel.append(nameSplit[1])\n",
    "radioIndex, radioTokenizer = tokenize_labels(radioLabel)\n",
    "print(radioIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<OOV>': 1, '60': 2, '137': 3, '152': 4}\n"
     ]
    }
   ],
   "source": [
    "# Create a tokenizer for the atomic number value part of data\n",
    "atomLabel = []\n",
    "for fileName in FileListMain:\n",
    "    nameSplit = fileName.split(\"-\")\n",
    "    if len(nameSplit) == 7:\n",
    "        atomLabel.append(nameSplit[2])\n",
    "atomIndex, atomTokenizer = tokenize_labels(atomLabel)\n",
    "print(atomIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<OOV>': 1, '40sec': 2, '50sec': 3, '55sec': 4, '10sec': 5, '15sec': 6, '20sec': 7, '25sec': 8, '30sec': 9, '35sec': 10, '45sec': 11, '5sec': 12, '60sec': 13}\n"
     ]
    }
   ],
   "source": [
    "# Create a tokenizer for the duration/time part of data\n",
    "timeLabel = []\n",
    "for fileName in FileListMain:\n",
    "    nameSplit = fileName.split(\"-\")\n",
    "    timeLabel.append(nameSplit[-3])\n",
    "timeIndex, timeTokenizer = tokenize_labels(timeLabel)\n",
    "print(timeIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<OOV>': 1, '120cm': 2, '110cm': 3, '40cm': 4, '30cm': 5}\n"
     ]
    }
   ],
   "source": [
    "# Create a tokenizer for the distance part of data\n",
    "distanceLabel = []\n",
    "for fileName in FileListMain:\n",
    "    nameSplit = fileName.split(\"-\")\n",
    "    distanceLabel.append(nameSplit[-2])\n",
    "distanceIndex, distanceTokenizer = tokenize_labels(distanceLabel)\n",
    "print(distanceIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<OOV>': 1, '0': 2, '1': 3, '10': 4, '2': 5, '3': 6, '4': 7, '5': 8, '6': 9, '7': 10, '8': 11, '9': 12, '11': 13, '12': 14, '13': 15, '14': 16, '15': 17, '16': 18, '17': 19, '18': 20, '19': 21, '20': 22, '21': 23, '22': 24, '23': 25, '24': 26, '25': 27, '26': 28, '27': 29, '28': 30, '29': 31, '30': 32, '31': 33, '32': 34, '33': 35, '34': 36, '35': 37, '36': 38, '37': 39, '38': 40, '39': 41, '40': 42, '41': 43, '42': 44, '43': 45, '44': 46, '45': 47, '46': 48, '47': 49, '48': 50, '49': 51}\n"
     ]
    }
   ],
   "source": [
    "# Create a tokenizer for the iteration part of data\n",
    "iterationLabel = []\n",
    "for fileName in FileListMain:\n",
    "    nameSplit = fileName.split(\"-\")\n",
    "    iterationSplit = nameSplit[-1].split('.')\n",
    "    iterationLabel.append(iterationSplit[0])\n",
    "iterationIndex, iterationTokenizer = tokenize_labels(iterationLabel)\n",
    "print(iterationIndex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define All the Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upscale\n",
    "def upscale(data, size=(64, 64)):\n",
    "    data = resize(data, (size[0], size[1], data.shape[2]), mode='constant')\n",
    "    return data  # Return the upscaled data\n",
    "\n",
    "# Descale\n",
    "def descale(data, size=(16, 16)):\n",
    "    data = resize(data, (size[0], size[1], data.shape[2]), mode='constant')\n",
    "    return data  # Return the descaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To colormap data\n",
    "def color_maps(data):\n",
    "    cm = plt.get_cmap('viridis')\n",
    "    mapped_data = cm(data)\n",
    "    mapped_data = np.uint8(mapped_data * 255)\n",
    "    return mapped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find the index of non-oov string according to the used tokenizer\n",
    "def index_finder(nameSplit, tokenizer):\n",
    "    tokenizedNameSplit = tokenizer.texts_to_sequences(nameSplit)\n",
    "    enumerateTokenized = enumerate(tokenizedNameSplit)\n",
    "    rawIndex = [index for index, value in enumerateTokenized if value!=[1]] # OOV tokens at 1\n",
    "    return rawIndex[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the spectra data to the range [0, 255]\n",
    "def normalize_count(x):\n",
    "    normalized_count = []\n",
    "    for i in x:\n",
    "        norm = int((i/max(x)) * 255)\n",
    "        normalized_count.append(norm)\n",
    "    return normalized_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preshuffle data and labels to avoid bias\n",
    "def preshuffle_data_label(data, label):\n",
    "    random_index = np.random.permutation(data.shape[0])\n",
    "    preshuffled_data = data[random_index]\n",
    "    preshuffled_label = [label[i] for i in random_index]\n",
    "    return preshuffled_data, preshuffled_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hilbert curve type of transformation\n",
    "def hilbert_curve(data):\n",
    "    # Check if data is 2D-transformable\n",
    "    number_of_data = len(data)\n",
    "    m, n = (int(math.sqrt(number_of_data)), int(math.sqrt(number_of_data)))\n",
    "    if m*n == number_of_data:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\"Sorry, but your data isn't Square 2D-transformable\")\n",
    "    if m == 2:\n",
    "        raise ValueError(\"2 x 2 data isn't compatible with Hilbert Curve\")\n",
    "    # Check if the dimension of the resulting 2D matrix is a power of 2\n",
    "    i = m\n",
    "    count = 1\n",
    "    while True:\n",
    "        if i%2 == 0:\n",
    "            if i == 2:\n",
    "                break\n",
    "            else:\n",
    "                i = i/2\n",
    "                count += 1\n",
    "        else:\n",
    "            raise ValueError(\"The dimension of 2D shows that it's not compatible with Hilbert curve\")\n",
    "    # Create placeholder matrix for resulting transformation\n",
    "    transformed = [[0]*n for _ in range(m)]\n",
    "    # Obtain hilbert index\n",
    "    hilbert_index = decode(range(len(data)), 2, count)\n",
    "    # Place data into placeholder matrix according to hilbert index\n",
    "    count = 0\n",
    "    for i,j in hilbert_index:\n",
    "        transformed[j][i] = data[count]\n",
    "        count += 1\n",
    "    return transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero Padding\n",
    "# To pad the data so that it consistently shaped (1, 1024) or (32, 32)\n",
    "def zero_padding(data):\n",
    "    shape = (32, 32)\n",
    "    numData = shape[0]*shape[1]\n",
    "    if len(data) < numData:\n",
    "        remainderData = numData - len(data)\n",
    "        zeroPad = [0 for _ in range(remainderData)]\n",
    "        data = data + zeroPad\n",
    "    elif len(data) == numData:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\"Number of data exceeds values supported by the algorithm\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate tweaking\n",
    "def learning_rate_variation(lr):\n",
    "    return lr * tf.math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather filenames of similar distance\n",
    "def search_distance_data(preferDistance):\n",
    "    filesNeeded = []\n",
    "    for filename in FileListMain:\n",
    "        nameSplit = filename.split('-')\n",
    "        distanceTag = nameSplit[index_finder(nameSplit, distanceTokenizer)]\n",
    "        if (preferDistance == distanceTag):\n",
    "            filesNeeded.append(filename)\n",
    "    if len(filesNeeded) == 0:\n",
    "        raise ValueError(\"Wrong inquiry parameters, please try again\")\n",
    "    return filesNeeded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather filenames of similar time\n",
    "def search_time_data(preferTime):\n",
    "    filesNeeded = []\n",
    "    for filename in FileListMain:\n",
    "        nameSplit = filename.split('-')\n",
    "        timeTag = nameSplit[index_finder(nameSplit, timeTokenizer)]\n",
    "        if (preferTime == timeTag):\n",
    "            filesNeeded.append(filename)\n",
    "    if len(filesNeeded) == 0:\n",
    "        raise ValueError(\"Wrong inquiry parameters, please try again\")\n",
    "    return filesNeeded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the raw_data_plot() function\n",
    "def raw_data_plot(selectMethod):\n",
    "    for fileName in FileListMain:\n",
    "        nameSplit = fileName.split(\"-\")\n",
    "        radioTag = nameSplit[1]\n",
    "        atomTag = nameSplit[2]\n",
    "        timeTag = nameSplit[index_finder(nameSplit, timeTokenizer)]\n",
    "        distanceTag = nameSplit[index_finder(nameSplit, distanceTokenizer)]\n",
    "        iterationSplit = nameSplit[-1].split('.')\n",
    "        iterationTag = iterationSplit[index_finder(iterationSplit, iterationTokenizer)]\n",
    "\n",
    "        if radioTag not in ['BckGnd', 'Co', 'Cs', 'Eu']:\n",
    "            continue\n",
    "            \n",
    "        path = MainFolder + f'\\{fileName}'\n",
    "        data = open(path)\n",
    "        data = json.load(data)\n",
    "        data = data['histogram']\n",
    "        data = zero_padding(data)\n",
    "        \n",
    "        if selectMethod == 'Normal':\n",
    "            data = np.array(data)\n",
    "            plt.title(f'{radioTag} {atomTag} 1K {timeTag} {distanceTag} {iterationTag}')\n",
    "            save_path = os.path.join(rawPlotPath, f'{fileName.split(\".json\")[0]}.png')\n",
    "            plt.ylabel('Counts')\n",
    "\n",
    "        else:\n",
    "            data = np.array(data)\n",
    "            data = normalize_count(data)\n",
    "            plt.title(f'{radioTag} {atomTag} 1K {timeTag} {distanceTag} {iterationTag}')\n",
    "            save_path = os.path.join(normalizedRawPath, f'{fileName.split(\".json\")[0]}.png')\n",
    "            plt.ylabel('Normalized Counts')\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(data, color='darkcyan', linewidth=1, markersize=1)\n",
    "        plt.xlabel('Energy Bin/Channel')\n",
    "        plt.title(f'{radioTag} {atomTag} {timeTag} {distanceTag} {iterationTag}')\n",
    "        \n",
    "        # Check if the file already exists\n",
    "        if os.path.exists(save_path):\n",
    "            os.remove(save_path)  # Remove the existing file\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for RawMode in RawMethod:\n",
    "    raw_data_plot(RawMode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tanpa Normalisasi\n",
    "first = True\n",
    "count = 0\n",
    "totalBack = None  # Initialize totalBack as None\n",
    "for filename in FileListMain:\n",
    "    path = MainFolder + f'\\{filename}'\n",
    "    nameSplit = filename.split('-')\n",
    "    if nameSplit[index_finder(nameSplit, radioTokenizer)] == 'BckGnd':\n",
    "        count += 1\n",
    "        with open(path) as fileopen:\n",
    "            filedata = json.load(fileopen)\n",
    "            filehist = filedata['histogram']\n",
    "            filehist = zero_padding(filehist)\n",
    "            filehist = np.array(filehist)\n",
    "        if first == True:\n",
    "            totalBack = filehist\n",
    "            first = False\n",
    "        else:\n",
    "            totalBack = totalBack + filehist\n",
    "\n",
    "if count != 0:\n",
    "    totalBack = totalBack/count  # Compute the average histogram\n",
    "\n",
    "    # Plot the average histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(totalBack, color='darkcyan', linewidth=1, markersize=1)\n",
    "    plt.xlabel('Energi Bin/Channel')\n",
    "    plt.ylabel('Counts')\n",
    "    plt.title('Rata-Rata Background Spectrum')\n",
    "else:\n",
    "    print(\"No background files found.\")\n",
    "\n",
    "save_path = os.path.join(backgroundPath, 'Average_Background_Spectrum.png')\n",
    "# Check if the file already exists\n",
    "if os.path.exists(save_path):\n",
    "    os.remove(save_path)  # Remove the existing file\n",
    "plt.savefig(save_path)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisasi sebelum Rata-rata\n",
    "first = True\n",
    "count = 0\n",
    "totalBack = None  # Initialize totalBack as None\n",
    "for filename in FileListMain:\n",
    "    path = MainFolder + f'\\{filename}'\n",
    "    nameSplit = filename.split('-')\n",
    "    if nameSplit[index_finder(nameSplit, radioTokenizer)] == 'BckGnd':\n",
    "        count += 1\n",
    "        with open(path) as fileopen:\n",
    "            filedata = json.load(fileopen)\n",
    "            filehist = filedata['histogram']\n",
    "            filehist = zero_padding(filehist)\n",
    "            filehist = normalize_count(filehist)\n",
    "            filehist = np.array(filehist)\n",
    "        if first == True:\n",
    "            totalBacknorm = filehist\n",
    "            first = False\n",
    "        else:\n",
    "            totalBacknorm = totalBacknorm + filehist\n",
    "\n",
    "if count != 0:\n",
    "    totalBacknorm = totalBacknorm/count  # Compute the average histogram\n",
    "\n",
    "    # Plot the average histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(totalBacknorm, color='darkcyan', linewidth=1, markersize=1)\n",
    "    plt.xlabel('Energi Bin/Channel')\n",
    "    plt.ylabel('Counts')\n",
    "    plt.title('Rata-Rata Background Spectrum')\n",
    "else:\n",
    "    print(\"No background files found.\")\n",
    "    \n",
    "save_path = os.path.join(backgroundPath, 'Normalized_Average_Background_Spectrum.png')\n",
    "# Check if the file already exists\n",
    "if os.path.exists(save_path):\n",
    "    os.remove(save_path)  # Remove the existing file\n",
    "plt.savefig(save_path)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Background Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define remove_background() function\n",
    "def remove_background(selectMethod, totalBacknorm):\n",
    "    for fileName in FileListMain:\n",
    "        nameSplit = fileName.split(\"-\")\n",
    "        radioTag = nameSplit[index_finder(nameSplit, radioTokenizer)]\n",
    "        timeTag = nameSplit[index_finder(nameSplit, timeTokenizer)]\n",
    "        distanceTag = nameSplit[index_finder(nameSplit, distanceTokenizer)]\n",
    "        iterationSplit = nameSplit[-1].split('.')\n",
    "        iterationTag = iterationSplit[index_finder(iterationSplit, iterationTokenizer)]\n",
    "        \n",
    "        path = MainFolder + f'\\{fileName}'\n",
    "        if radioTag not in ['Co', 'Cs', 'Eu']:\n",
    "            continue\n",
    "        \n",
    "        data = open(path)\n",
    "        data = json.load(data)\n",
    "        data = data['histogram']\n",
    "        data = zero_padding(data)\n",
    "        data = normalize_count(data)\n",
    "        data = np.array(data)\n",
    "        data = data - totalBacknorm\n",
    "\n",
    "        if selectMethod == 'Normal':\n",
    "            save_path = os.path.join(removedBackgroundPath, f'{fileName.split(\".json\")[0]}.png')\n",
    "\n",
    "        else:\n",
    "            data = [i if i > 0 else 0 for i in data]\n",
    "            save_path = os.path.join(removedBackgroundPathNonZero, f'{fileName.split(\".json\")[0]}.png')\n",
    "            \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.title(f'Removed Background {radioTag} {timeTag} {distanceTag}-{iterationTag}')\n",
    "        plt.plot(data, color='darkcyan', linewidth=1, markersize=1)\n",
    "        plt.xlabel('Energy Bin/Channel')\n",
    "        plt.ylabel('Counts')\n",
    "        \n",
    "        # Check if the file already exists\n",
    "        if os.path.exists(save_path):\n",
    "            os.remove(save_path)  # Remove the existing file\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in BgMethod:\n",
    "    remove_background(method, totalBacknorm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Transformation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save transformed and colormapped spectra gamma data\n",
    "def transformed_data_save(fileName, selectTransform, data, transformedPath, radioTag, atomTag, timeTag, distanceTag, iterationTag): \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(data, cmap='viridis')\n",
    "    plt.xlabel('Energy Bin/Channel')\n",
    "    plt.ylabel('Normalized Counts')\n",
    "    \n",
    "    save_path = os.path.join(transformedPath, f'{selectTransform}-{fileName.split(\".json\")[0]}.png')\n",
    "    \n",
    "    plt.title(f'{selectTransform} Transformed {radioTag} {atomTag} 1K {timeTag} {distanceTag} {iterationTag}')\n",
    "\n",
    "    # Check if the file already exists\n",
    "    if os.path.exists(save_path):\n",
    "        os.remove(save_path)  # Remove the existing file\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gama spectra data preprocessing\n",
    "def data_preprocess_image(selectTransform):       \n",
    "    for fileName in FileListMain:\n",
    "        nameSplit = fileName.split('-')\n",
    "        iterationSplit = nameSplit[-1].split('.')\n",
    "        radioTag = nameSplit[index_finder(nameSplit, radioTokenizer)]\n",
    "        timeTag = nameSplit[index_finder(nameSplit, timeTokenizer)]\n",
    "        distanceTag = nameSplit[index_finder(nameSplit, distanceTokenizer)]\n",
    "        iterationTag = iterationSplit[index_finder(iterationSplit, iterationTokenizer)]\n",
    "        \n",
    "        path = MainFolder + f'\\{fileName}'\n",
    "        if radioTag not in ['Co', 'Cs', 'Eu']:\n",
    "            continue\n",
    "            \n",
    "        fileopen = open(path)\n",
    "        filedata = json.load(fileopen)\n",
    "        data = filedata['histogram']\n",
    "        data = zero_padding(data)              \n",
    "        data = normalize_count(data) - totalBacknorm\n",
    "        data = hilbert_curve(data)\n",
    "        data = color_maps(data)\n",
    "        data = np.array(data)\n",
    "        \n",
    "                # Use Upscale/Descale method\n",
    "        if selectTransform == 'Upscale':\n",
    "            data = upscale(data)\n",
    "        elif selectTransform == 'Descale':\n",
    "            data = descale(data)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        # Save the transformed and colormapped data\n",
    "        \n",
    "        if selectTransform == 'Upscale':\n",
    "            transformed_data_save(fileName, selectTransform, data, transformedPath, radioTag, radioTag, timeTag, distanceTag, iterationTag)\n",
    "        elif selectTransform == 'Descale':\n",
    "            transformed_data_save(fileName, selectTransform, data, transformedPath, radioTag, radioTag, timeTag, distanceTag, iterationTag)\n",
    "        elif selectTransform == 'Normal':\n",
    "            transformed_data_save(fileName, selectTransform, data, transformedPath, radioTag, radioTag, timeTag, distanceTag, iterationTag)\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Transformation and Colormapping\n",
    "for transform in transformMethod:\n",
    "    data_preprocess_image(transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gama spectra data preprocessing\n",
    "def data_preprocess(selectTransform):\n",
    "    totalLabel = []\n",
    "    if selectTransform == 'Upscale':\n",
    "        placeHolder = np.zeros((1, 64, 64, 4))\n",
    "    elif selectTransform == 'Descale':\n",
    "        placeHolder = np.zeros((1, 16, 16, 4))\n",
    "    else:\n",
    "        placeHolder= np.zeros((1, 32, 32, 4))\n",
    "    first = True\n",
    "        \n",
    "    for fileName in FileListMain:\n",
    "        nameSplit = fileName.split('-')\n",
    "        iterationSplit = nameSplit[-1].split('.')\n",
    "        radioTag = nameSplit[index_finder(nameSplit, radioTokenizer)]\n",
    "        timeTag = nameSplit[index_finder(nameSplit, timeTokenizer)]\n",
    "        distanceTag = nameSplit[index_finder(nameSplit, distanceTokenizer)]\n",
    "        iterationTag = iterationSplit[index_finder(iterationSplit, iterationTokenizer)]\n",
    "        \n",
    "        path = MainFolder + f'\\{fileName}'\n",
    "        if radioTag not in ['Co', 'Cs', 'Eu']:\n",
    "            continue\n",
    "            \n",
    "        fileopen = open(path)\n",
    "        filedata = json.load(fileopen)\n",
    "        data = filedata['histogram']\n",
    "        data = zero_padding(data)              \n",
    "        data = normalize_count(data) - totalBacknorm\n",
    "        data = hilbert_curve(data)\n",
    "        data = color_maps(data)\n",
    "        data = np.array(data)\n",
    "        \n",
    "                # Use Upscale/Descale method\n",
    "        if selectTransform == 'Upscale':\n",
    "            data = upscale(data)\n",
    "        elif selectTransform == 'Descale':\n",
    "            data = descale(data)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        # Save the transformed and colormapped data\n",
    "        data = np.expand_dims(data, axis=0)\n",
    "        \n",
    "        # if first then stack with placeholder, otherwise stack with the final data       \n",
    "        if first == True:\n",
    "            totalData = np.vstack((placeHolder, data))\n",
    "            first = False\n",
    "        else:\n",
    "            totalData = np.vstack((totalData, data))\n",
    "        \n",
    "        if radioTag in radioIndex:  # Check if radioTag is a valid radioIndex\n",
    "        # Process data and save plot\n",
    "            if radioTag == 'Co':\n",
    "                totalLabel.append([1, 0, 0])\n",
    "            elif radioTag == 'Cs':\n",
    "                totalLabel.append([0, 1, 0])\n",
    "            elif radioTag == 'Eu':\n",
    "                totalLabel.append([0, 0, 1])\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            print(f\"Ignore file '{fileName}' as it has invalid radioTag '{radioTag}'.\")\n",
    "        fileopen.close()\n",
    "    if useColormap == True:\n",
    "        pass\n",
    "    else:\n",
    "        totalData = np.expand_dims(totalData, axis=-1)\n",
    "        \n",
    "        # Close the file\n",
    "    totalData = totalData[1:] # To erase placeholder data on top\n",
    "    radioID = [radioIndex['Co'], radioIndex['Cs'], radioIndex['Eu']] # 3 for Co-60, 4 for Cs-137, 5 for Eu-152\n",
    "    return totalData, totalLabel, radioID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model architecture\n",
    "def create_cnn_model(input_dims):\n",
    "  model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.InputLayer(input_shape=input_dims),\n",
    "      tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "      tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2, 2),\n",
    "      tf.keras.layers.Dropout(0.1),\n",
    "      tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "      tf.keras.layers.Dropout(0.1),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(units=256, activation='relu'),\n",
    "      tf.keras.layers.Dropout(0.1),\n",
    "      tf.keras.layers.Dense(units=3, activation='softmax')\n",
    "  ])\n",
    "  model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics = ['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN Model architecture\n",
    "def create_ann_model(input_dims):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=input_dims),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(units=256, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(units=3, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_model_train(preshuffled_data, preshuffled_label, input_dims, selectTransform, selectModel, radioID):\n",
    "    inputs = np.array(preshuffled_data)\n",
    "    outputs = np.array(preshuffled_label)\n",
    "\n",
    "    # Defining K-fold\n",
    "    kFold = KFold(n_splits=foldAmount, shuffle=True, random_state=13)\n",
    "\n",
    "    # K-fold commencing\n",
    "    accPerFold = []\n",
    "    lossPerFold = []\n",
    "    historyPerFold = []\n",
    "    rocPerFold = []\n",
    "    modelPerFold = []\n",
    "    classRepPerFold = []\n",
    "    foldNumber = 1\n",
    "\n",
    "    print('--------------------------------------')\n",
    "    print(f'{selectModel} MODEL WITH {selectTransform} TRANSFORMATION')\n",
    "\n",
    "    for train, test in kFold.split(inputs):\n",
    "        if selectModel == 'CNN':\n",
    "            model_creator = create_cnn_model\n",
    "        elif selectModel == 'ANN':\n",
    "            model_creator = create_ann_model\n",
    "        else:\n",
    "            raise ValueError(\"Invalid model type. Use 'CNN' or 'ANN'.\")\n",
    "\n",
    "        model = model_creator(input_dims)\n",
    "        \n",
    "        print('--------------------------------------')\n",
    "        print(f'Training for fold no-{foldNumber}')\n",
    "        \n",
    "        train_data, val_data = inputs[train], inputs[test]\n",
    "        train_labels, val_labels = outputs[train], outputs[test]\n",
    "\n",
    "        history = model.fit(train_data, train_labels,\n",
    "                            epochs=30,\n",
    "                            verbose=0,\n",
    "                            validation_data=(val_data, val_labels))\n",
    "        \n",
    "        rocPerRadio = []\n",
    "        for i in range(len(radioID)):\n",
    "            y_predict = model.predict(val_data, verbose=0)[:, i]\n",
    "            y_test = val_labels[:, i]\n",
    "            fpr, tpr, thresholds = roc_curve(y_test, y_predict)\n",
    "            rocPerRadio.append((fpr, tpr))\n",
    "        rocPerFold.append(rocPerRadio)\n",
    "        y_predict = model.predict(val_data, verbose=0)\n",
    "        y_true = outputs[test].argmax(axis=-1)\n",
    "        y_pred = y_predict.argmax(axis=-1)\n",
    "        print(f'y_true: {y_true}')\n",
    "        print(f'y_pred: {y_pred}')\n",
    "        print(y_predict)\n",
    "        print(outputs[test])\n",
    "        # Classification report for the best model\n",
    "        classRep = classification_report(y_true, \n",
    "                                        y_pred, \n",
    "                                        labels=val_labels,\n",
    "                                        target_names=['Co', 'Cs', 'Eu'],\n",
    "                                        output_dict=True,\n",
    "                                        zero_division=0.0,\n",
    "                                        digits=2)\n",
    "        for radio in classRep:\n",
    "            if isinstance(classRep[radio], dict):\n",
    "                for metric, value in classRep[radio].items():\n",
    "                    classRep[radio][metric] = '{:.2f}'.format(value)\n",
    "        classRepPerFold.append(classRep)\n",
    "        evaluation = model.evaluate(val_data, val_labels, verbose=0)\n",
    "\n",
    "        print(f'Evaluation for fold no-{foldNumber}:')\n",
    "        print(f'{model.metrics_names[0]} of {evaluation[0]}')\n",
    "        print(f'{model.metrics_names[1]} of {evaluation[1]}')\n",
    "        \n",
    "        accPerFold.append(evaluation[1] * 100)\n",
    "        lossPerFold.append(evaluation[0])\n",
    "        historyPerFold.append((history.history['loss'], \n",
    "                            history.history['accuracy'], \n",
    "                            history.history['val_loss'], \n",
    "                            history.history['val_accuracy']))\n",
    "        modelPerFold.append(model)\n",
    "        foldNumber += 1\n",
    "        \n",
    "\n",
    "    # Finding best model from all folds\n",
    "    if np.argmax(accPerFold) == np.argmin(lossPerFold):\n",
    "        bestModelIndex = np.argmax(accPerFold)\n",
    "    else:\n",
    "        bestModelIndex = np.argmin(lossPerFold)\n",
    "    \n",
    "    print('--------------------------------------')\n",
    "    print(f'Best model is found to be fold no-{bestModelIndex+1}')\n",
    "           \n",
    "    # Save the best model according to the folds's metrics in .h5 file\n",
    "    destinationFile = f'{modelSavePath}\\{selectTransform}.h5'\n",
    "    if os.path.isfile(destinationFile):\n",
    "        os.remove(destinationFile)\n",
    "        modelPerFold[bestModelIndex].save(destinationFile)\n",
    "    else:\n",
    "        modelPerFold[bestModelIndex].save(destinationFile)\n",
    "    \n",
    "    # Mean accuracy and mean loss for all folds\n",
    "    print('--------------------------------------')\n",
    "    print(f'Mean test accuracy of all folds are found to be: {sum(accPerFold)/len(accPerFold)}')\n",
    "    print(f'Mean test loss of all folds are found to be: {sum(lossPerFold)/len(lossPerFold)}')\n",
    "    \n",
    "    return rocPerFold, bestModelIndex, historyPerFold, modelPerFold, classRepPerFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_roc_plot(selectTransform, selectMethod, bestModelIndex, radioID, tokenizer1, tokenizer2, rocPerFold, savefolder):\n",
    "    if bestModelIndex >= len(rocPerFold):\n",
    "        return\n",
    "\n",
    "    for id in radioID:\n",
    "        index = id - 3\n",
    "        if index < 0 or index >= len(rocPerFold[bestModelIndex]):\n",
    "            print(f'No data available for Radio ID: {id} at index: {index}')\n",
    "            continue\n",
    "        \n",
    "        fpr, tpr = rocPerFold[bestModelIndex][index]\n",
    "\n",
    "        if fpr.size > 0 and tpr.size > 0:  # Use .size to check for non-empty numpy arrays\n",
    "            label_text = f'{tokenizer1.sequences_to_texts([[id]])[0].capitalize()}-{tokenizer2.sequences_to_texts([[id-1]])[0]}'\n",
    "            plt.plot(fpr, tpr, label=label_text)\n",
    "\n",
    "    plt.title(f'{selectMethod} Model of ROC curve with {selectTransform}')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend()\n",
    "\n",
    "    destinationFile = os.path.join(savefolder, f'{selectMethod}_Model_of_ROC_curve_with_{selectTransform}.png')\n",
    "    if os.path.isfile(destinationFile):\n",
    "        os.remove(destinationFile)\n",
    "    plt.savefig(destinationFile)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_learning_plot(selectTransform, bestModelIndex, selectMethod, historyPerFold, savefolder):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(f'Learning Curve for Fold no {bestModelIndex+1} | {selectMethod} Model with {selectTransform} Transformation') \n",
    "    plt.plot(((historyPerFold[bestModelIndex][0])), label=['Loss'])\n",
    "    plt.plot(((historyPerFold[bestModelIndex][-2])), label=['Val_Loss'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()    \n",
    "    destinationFile = f'{savefolder}\\{selectMethod} Model of Learning_curve_with_{selectTransform}.png'\n",
    "    if os.path.isfile(destinationFile):\n",
    "            os.remove(destinationFile)\n",
    "            plt.savefig(destinationFile)\n",
    "    else:\n",
    "            plt.savefig(destinationFile)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_accuracy_val(selectTransform, bestModelIndex, selectMethod, historyPerFold, savefolder):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(historyPerFold[bestModelIndex][1], label='Accuracy')\n",
    "    plt.plot(historyPerFold[bestModelIndex][-1], label='Validation Accuracy')\n",
    "    plt.title(f'{selectMethod} Model of Accuracy and Validation Accuracy with {selectTransform}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    destinationFile = f'{savefolder}\\{selectMethod} Model of Accuracy and Validation Accuracy with {selectTransform}.png'\n",
    "    if os.path.isfile(destinationFile):\n",
    "        os.remove(destinationFile)\n",
    "        plt.savefig(destinationFile)\n",
    "    else:\n",
    "        plt.savefig(destinationFile)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bestacc_for_model_transform(selectTransform, bestModelIndex, selectMethod, historyPerFold, savefolder):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title('Best Accuracy for Every Model and Transformation')\n",
    "\n",
    "    best_acc = {}  # Dictionary to store the best accuracy for each combination of model and transformation\n",
    "    for model in selectMethod:\n",
    "        for transform in selectTransform:      \n",
    "            acc = historyPerFold[bestModelIndex][-1][-1]\n",
    "            best_acc[f'{model} with {transform}'] = acc\n",
    "\n",
    "    # Plot the best accuracy for each combination of model and transformation\n",
    "    plt.bar(best_acc.keys(), best_acc.values())\n",
    "\n",
    "    plt.ylabel('Best Accuracy')\n",
    "\n",
    "    destinationFile = f'{savefolder}\\Best_Accuracy_for_Every_Model_and_Transformation.png'\n",
    "    if os.path.isfile(destinationFile):\n",
    "        os.remove(destinationFile)\n",
    "        plt.savefig(destinationFile)\n",
    "    else:\n",
    "        plt.savefig(destinationFile)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_per_fold(selectTransform, selectModel, historyPerFold, savefolder):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for fold, history in enumerate(historyPerFold, 1):\n",
    "        val_accuracy = history[3]  # Validation accuracy from history\n",
    "        plt.plot(val_accuracy, label=f'Fold {fold}')\n",
    "\n",
    "    plt.title(f'Accuracy for {selectModel} Model {selectTransform} Transformation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    destinationFile = f'{savefolder}\\{selectModel} Model Accuracy with_{selectTransform}.png'\n",
    "    if os.path.isfile(destinationFile):\n",
    "            os.remove(destinationFile)\n",
    "            plt.savefig(destinationFile)\n",
    "    else:\n",
    "            plt.savefig(destinationFile)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_auc_per_fold(selectModel, selectTransform, roc_per_fold, radioID, savefolder):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for fold, roc_data in enumerate(roc_per_fold, 1):\n",
    "        for i, (fpr, tpr) in enumerate(roc_data):\n",
    "            label = ''\n",
    "            if radioID[i] == 3:\n",
    "                label = 'Co-60'\n",
    "                plt.plot(fpr, tpr, label=f'Fold {fold}, {label}')\n",
    "            elif radioID[i] == 4:\n",
    "                label = 'Cs-137'\n",
    "                plt.plot(fpr, tpr, label=f'Fold {fold}, {label}')\n",
    "            elif radioID[i] == 5:\n",
    "                label = 'Eu-152'\n",
    "                plt.plot(fpr, tpr, label=f'Fold {fold}, {label}')\n",
    "\n",
    "\n",
    "    plt.title('AOC Curve per Fold')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend()\n",
    "    \n",
    "    destinationFile = f'{savefolder}/{selectModel}_Model_AUC_with_{selectTransform}.png'\n",
    "    if os.path.isfile(destinationFile):\n",
    "        os.remove(destinationFile)\n",
    "        plt.savefig(destinationFile)\n",
    "    else:\n",
    "        plt.savefig(destinationFile)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classification_matrix_per_fold(selectModel, selectTransform, model_per_fold, inputs, outputs, savefolder):\n",
    "    indices = np.arange(len(inputs))\n",
    "    np.random.shuffle(indices)\n",
    "    inputs = np.array(inputs)[indices]\n",
    "    outputs = np.array(outputs)[indices]\n",
    "    for fold, model in enumerate(model_per_fold, 1):\n",
    "        plt.figure(figsize=(8, 6))  # Adjust size if needed\n",
    "        \n",
    "        # Predict probabilities for each class\n",
    "        predicted_probabilities = model.predict(inputs)\n",
    "        predicted_labels = np.argmax(predicted_probabilities, axis=1)\n",
    "        \n",
    "        # Calculate confusion matrix\n",
    "        cm = confusion_matrix(outputs.argmax(axis=1), predicted_labels)\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', \n",
    "                    xticklabels=['Co-60', 'Cs-137', 'Eu-152'], \n",
    "                    yticklabels=['Co-60', 'Cs-137', 'Eu-152']) \n",
    "        plt.xlabel('Predicted labels')\n",
    "        plt.ylabel('True labels')\n",
    "        plt.title(f'{selectModel} with {selectTransform} Fold {fold} Classification Matrix')\n",
    "        \n",
    "        # Save figure with fold number in the file name\n",
    "        destinationFile = f'{savefolder}/{selectModel}_Model_Classification_Matrix_with_{selectTransform}_Fold_{fold}.png'\n",
    "        plt.savefig(destinationFile)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_class_rep(selectTransform, selectCmap, bestModelIndex, classRepPerFold, savefolder):\n",
    "    report = classRepPerFold[bestModelIndex]\n",
    "    pandasReport = pd.DataFrame(report).transpose()\n",
    "    destinationFile = f'{savefolder}\\Classification_Report_With_{selectTransform}_and_{selectCmap}.csv'\n",
    "    if os.path.isfile(destinationFile):\n",
    "        os.remove(destinationFile)\n",
    "        pandasReport.to_csv(destinationFile, index=True)\n",
    "    else:\n",
    "        pandasReport.to_csv(destinationFile, index=True)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_best(selectTransform, selectModel, bestModelIndex,historyPerFold, savefolder):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    val_accuracy = historyPerFold[0][3]  # Validation accuracy from history\n",
    "    plt.plot(val_accuracy, label='Validation Accuracy')\n",
    "    plt.title(f'Validation Accuracy for {selectModel} Model with {selectTransform} Transformation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    destinationFile = f'{savefolder}\\{selectModel} Model Validation Accuracy with_{selectTransform}.png'\n",
    "    if os.path.isfile(destinationFile):\n",
    "        os.remove(destinationFile)\n",
    "        plt.savefig(destinationFile)\n",
    "    else:\n",
    "        plt.savefig(destinationFile)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "ANN MODEL WITH Normal TRANSFORMATION\n",
      "--------------------------------------\n",
      "Training for fold no-1\n",
      "y_true: [1 2 2 0 1 1 0]\n",
      "y_pred: [1 0 2 0 1 1 0]\n",
      "[[6.5747959e-15 1.0000000e+00 0.0000000e+00]\n",
      " [9.9948150e-01 5.1855895e-04 5.2625984e-24]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [6.8436623e-01 3.1563380e-01 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 2.2076388e-30 0.0000000e+00]]\n",
      "[[0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]]\n",
      "Evaluation for fold no-1:\n",
      "loss of 7.7115254402160645\n",
      "accuracy of 0.8571428656578064\n",
      "--------------------------------------\n",
      "Training for fold no-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dinova\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true: [0 2 2 0 2 0 0]\n",
      "y_pred: [1 2 2 0 2 0 0]\n",
      "[[4.1637285e-22 1.0000000e+00 0.0000000e+00]\n",
      " [5.2384488e-29 2.7539392e-20 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 8.3921625e-19 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 2.0497062e-09 0.0000000e+00]\n",
      " [1.0000000e+00 1.2262325e-20 0.0000000e+00]]\n",
      "[[1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]]\n",
      "Evaluation for fold no-2:\n",
      "loss of 7.032923221588135\n",
      "accuracy of 0.8571428656578064\n",
      "--------------------------------------\n",
      "Training for fold no-3\n",
      "y_true: [1 2 1 0 0 2 2]\n",
      "y_pred: [0 2 1 0 0 2 2]\n",
      "[[1.0000000e+00 1.3142505e-21 0.0000000e+00]\n",
      " [7.2591643e-24 0.0000000e+00 1.0000000e+00]\n",
      " [5.1319734e-07 9.9999952e-01 4.2306479e-31]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [2.0708523e-27 0.0000000e+00 1.0000000e+00]]\n",
      "[[0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]]\n",
      "Evaluation for fold no-3:\n",
      "loss of 6.868717193603516\n",
      "accuracy of 0.8571428656578064\n",
      "--------------------------------------\n",
      "Training for fold no-4\n",
      "y_true: [1 2 0 0 2 2]\n",
      "y_pred: [0 2 0 0 2 2]\n",
      "[[1.0000000e+00 5.2249711e-09 0.0000000e+00]\n",
      " [1.6604873e-14 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [3.5458231e-01 0.0000000e+00 6.4541763e-01]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]]\n",
      "[[0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]]\n",
      "Evaluation for fold no-4:\n",
      "loss of 3.25127911567688\n",
      "accuracy of 0.8333333134651184\n",
      "--------------------------------------\n",
      "Training for fold no-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dinova\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\Dinova\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true: [1 1 1 0 1 1]\n",
      "y_pred: [1 0 1 0 1 0]\n",
      "[[2.7388665e-03 9.9726117e-01 0.0000000e+00]\n",
      " [1.0000000e+00 3.4315799e-15 0.0000000e+00]\n",
      " [4.3616248e-12 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.6993900e-38 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]]\n",
      "[[0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]]\n",
      "Evaluation for fold no-5:\n",
      "loss of 22.566930770874023\n",
      "accuracy of 0.6666666865348816\n",
      "--------------------------------------\n",
      "Best model is found to be fold no-4\n",
      "--------------------------------------\n",
      "Mean test accuracy of all folds are found to be: 81.42857193946838\n",
      "Mean test loss of all folds are found to be: 9.486275148391723\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "--------------------------------------\n",
      "CNN MODEL WITH Normal TRANSFORMATION\n",
      "--------------------------------------\n",
      "Training for fold no-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dinova\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true: [0 0 2 0 0 2 0]\n",
      "y_pred: [0 0 2 0 0 2 0]\n",
      "[[9.99407649e-01 5.92412078e-04 4.54272148e-10]\n",
      " [8.90424013e-01 1.08178005e-01 1.39800215e-03]\n",
      " [3.74285015e-22 7.72510565e-15 1.00000000e+00]\n",
      " [6.34716332e-01 3.48951370e-01 1.63322259e-02]\n",
      " [9.72538233e-01 2.74617355e-02 6.12970874e-09]\n",
      " [1.77976461e-22 1.50489247e-16 1.00000000e+00]\n",
      " [6.08402610e-01 3.91025394e-01 5.71997429e-04]]\n",
      "[[1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]]\n",
      "Evaluation for fold no-1:\n",
      "loss of 0.1565702110528946\n",
      "accuracy of 1.0\n",
      "--------------------------------------\n",
      "Training for fold no-2\n",
      "y_true: [2 1 2 1 2 0 2]\n",
      "y_pred: [2 1 2 1 2 0 2]\n",
      "[[2.6038195e-12 3.0590831e-21 1.0000000e+00]\n",
      " [1.8830339e-24 1.0000000e+00 0.0000000e+00]\n",
      " [3.3272967e-22 1.5601532e-34 1.0000000e+00]\n",
      " [1.1117056e-16 1.0000000e+00 2.9393473e-27]\n",
      " [3.0957172e-16 3.4944320e-23 1.0000000e+00]\n",
      " [9.9999952e-01 4.1827263e-07 2.8751539e-11]\n",
      " [5.4517008e-13 3.5697759e-15 1.0000000e+00]]\n",
      "[[0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]]\n",
      "Evaluation for fold no-2:\n",
      "loss of 6.811957575791894e-08\n",
      "accuracy of 1.0\n",
      "--------------------------------------\n",
      "Training for fold no-3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dinova\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true: [2 2 2 2 1 1 1]\n",
      "y_pred: [2 2 2 2 1 1 1]\n",
      "[[0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [4.3364466e-32 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.7912816e-08 1.0000000e+00 1.9001913e-11]\n",
      " [1.7989514e-15 1.0000000e+00 4.7615138e-08]\n",
      " [9.0423079e-21 7.7149266e-01 2.2850737e-01]]\n",
      "[[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]]\n",
      "Evaluation for fold no-3:\n",
      "loss of 0.03706115856766701\n",
      "accuracy of 1.0\n",
      "--------------------------------------\n",
      "Training for fold no-4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dinova\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true: [1 0 0 0 1 1]\n",
      "y_pred: [1 1 1 1 1 1]\n",
      "[[1.5378614e-31 1.0000000e+00 6.3702068e-21]\n",
      " [1.0920538e-06 9.9999893e-01 6.7056430e-11]\n",
      " [7.9102488e-11 1.0000000e+00 3.3290714e-16]\n",
      " [8.2886428e-02 9.1711360e-01 5.0008597e-09]\n",
      " [9.3699465e-29 1.0000000e+00 1.9610713e-18]\n",
      " [4.4511716e-31 1.0000000e+00 8.0169638e-27]]\n",
      "[[0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]]\n",
      "Evaluation for fold no-4:\n",
      "loss of 6.5796685218811035\n",
      "accuracy of 0.5\n",
      "--------------------------------------\n",
      "Training for fold no-5\n",
      "y_true: [0 1 2 1 1 0]\n",
      "y_pred: [0 1 2 1 1 0]\n",
      "[[9.9999988e-01 6.8484503e-08 5.5267406e-23]\n",
      " [6.1643270e-30 1.0000000e+00 0.0000000e+00]\n",
      " [6.6214112e-22 3.9630181e-01 6.0369825e-01]\n",
      " [6.5581318e-32 1.0000000e+00 0.0000000e+00]\n",
      " [1.6077172e-30 1.0000000e+00 4.0793937e-38]\n",
      " [9.8282510e-01 1.7174840e-02 6.8521574e-21]]\n",
      "[[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]]\n",
      "Evaluation for fold no-5:\n",
      "loss of 0.08700083941221237\n",
      "accuracy of 1.0\n",
      "--------------------------------------\n",
      "Best model is found to be fold no-2\n",
      "--------------------------------------\n",
      "Mean test accuracy of all folds are found to be: 90.0\n",
      "Mean test loss of all folds are found to be: 1.3720601598066906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dinova\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "--------------------------------------\n",
      "ANN MODEL WITH Upscale TRANSFORMATION\n",
      "--------------------------------------\n",
      "Training for fold no-1\n",
      "y_true: [1 1 2 0 0 0 0]\n",
      "y_pred: [1 1 2 0 0 0 0]\n",
      "[[0.06205379 0.91817284 0.01977332]\n",
      " [0.04457762 0.94109917 0.01432319]\n",
      " [0.03982111 0.04413339 0.9160455 ]\n",
      " [0.7371692  0.13655515 0.12627567]\n",
      " [0.80176294 0.1540761  0.04416108]\n",
      " [0.7266365  0.1514652  0.12189832]\n",
      " [0.700519   0.18188462 0.11759638]]\n",
      "[[0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]]\n",
      "Evaluation for fold no-1:\n",
      "loss of 0.20498691499233246\n",
      "accuracy of 1.0\n",
      "--------------------------------------\n",
      "Training for fold no-2\n",
      "y_true: [0 1 1 2 1 1 1]\n",
      "y_pred: [0 1 1 2 1 1 1]\n",
      "[[0.84120744 0.09782671 0.06096585]\n",
      " [0.3956695  0.56845194 0.03587866]\n",
      " [0.33011967 0.59132123 0.07855903]\n",
      " [0.02400933 0.00342868 0.972562  ]\n",
      " [0.37314904 0.59575963 0.03109128]\n",
      " [0.28643584 0.6832583  0.03030584]\n",
      " [0.38615426 0.572406   0.04143974]]\n",
      "[[1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]]\n",
      "Evaluation for fold no-2:\n",
      "loss of 0.39252567291259766\n",
      "accuracy of 1.0\n",
      "--------------------------------------\n",
      "Training for fold no-3\n",
      "y_true: [1 2 2 2 2 0 0]\n",
      "y_pred: [1 2 2 2 2 0 0]\n",
      "[[0.15566519 0.8393026  0.00503227]\n",
      " [0.02673157 0.00318763 0.9700808 ]\n",
      " [0.10650548 0.01550964 0.8779849 ]\n",
      " [0.06875735 0.0115589  0.9196837 ]\n",
      " [0.04985097 0.00614375 0.94400525]\n",
      " [0.8156171  0.13784842 0.04653448]\n",
      " [0.8168459  0.13769448 0.04545958]]\n",
      "[[0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]]\n",
      "Evaluation for fold no-3:\n",
      "loss of 0.1261642724275589\n",
      "accuracy of 1.0\n",
      "--------------------------------------\n",
      "Training for fold no-4\n",
      "y_true: [1 2 1 2 2 0]\n",
      "y_pred: [1 2 1 2 2 0]\n",
      "[[0.09386795 0.8924682  0.0136638 ]\n",
      " [0.00766795 0.00769931 0.98463273]\n",
      " [0.12888937 0.8643765  0.00673406]\n",
      " [0.03680263 0.02698905 0.9362083 ]\n",
      " [0.01160302 0.02189112 0.9665059 ]\n",
      " [0.94733864 0.04132775 0.01133353]]\n",
      "[[0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]]\n",
      "Evaluation for fold no-4:\n",
      "loss of 0.0715135931968689\n",
      "accuracy of 1.0\n",
      "--------------------------------------\n",
      "Training for fold no-5\n",
      "y_true: [0 2 0 1 0 2]\n",
      "y_pred: [0 2 0 1 0 2]\n",
      "[[0.68119824 0.24831861 0.07048316]\n",
      " [0.12853785 0.02318431 0.84827787]\n",
      " [0.80183697 0.13377744 0.06438569]\n",
      " [0.13015139 0.8215701  0.04827846]\n",
      " [0.7749577  0.12672846 0.0983138 ]\n",
      " [0.14845784 0.03502678 0.8165154 ]]\n",
      "[[1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]]\n",
      "Evaluation for fold no-5:\n",
      "loss of 0.23724888265132904\n",
      "accuracy of 1.0\n",
      "--------------------------------------\n",
      "Best model is found to be fold no-4\n",
      "--------------------------------------\n",
      "Mean test accuracy of all folds are found to be: 100.0\n",
      "Mean test loss of all folds are found to be: 0.20648786723613738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dinova\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 18ms/step\n",
      "--------------------------------------\n",
      "CNN MODEL WITH Upscale TRANSFORMATION\n",
      "--------------------------------------\n",
      "Training for fold no-1\n",
      "y_true: [1 1 1 0 2 0 1]\n",
      "y_pred: [1 1 1 0 2 0 1]\n",
      "[[0.15175802 0.83815396 0.01008801]\n",
      " [0.1108688  0.87599266 0.01313852]\n",
      " [0.12372719 0.8507876  0.02548527]\n",
      " [0.940819   0.03105105 0.02812988]\n",
      " [0.08387332 0.00468803 0.91143864]\n",
      " [0.96376723 0.01544935 0.02078338]\n",
      " [0.09272733 0.8988911  0.00838158]]\n",
      "[[0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]]\n",
      "Evaluation for fold no-1:\n",
      "loss of 0.1096825823187828\n",
      "accuracy of 1.0\n",
      "--------------------------------------\n",
      "Training for fold no-2\n",
      "y_true: [0 2 0 1 0 2 0]\n",
      "y_pred: [0 2 0 1 0 2 0]\n",
      "[[9.8004031e-01 1.7246537e-02 2.7131576e-03]\n",
      " [4.0058317e-03 2.8435036e-03 9.9315065e-01]\n",
      " [9.0407497e-01 8.4470890e-02 1.1454154e-02]\n",
      " [2.0703401e-02 9.7865504e-01 6.4152235e-04]\n",
      " [9.7284615e-01 1.6765678e-02 1.0388249e-02]\n",
      " [3.2740580e-03 1.3145678e-03 9.9541134e-01]\n",
      " [9.7603476e-01 1.8511223e-02 5.4540411e-03]]\n",
      "[[1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]]\n",
      "Evaluation for fold no-2:\n",
      "loss of 0.02940560318529606\n",
      "accuracy of 1.0\n",
      "--------------------------------------\n",
      "Training for fold no-3\n",
      "y_true: [2 1 0 2 1 0 0]\n",
      "y_pred: [2 1 0 2 1 0 0]\n",
      "[[5.6481687e-03 2.1729556e-04 9.9413460e-01]\n",
      " [2.2516241e-03 9.9455619e-01 3.1922399e-03]\n",
      " [9.9267417e-01 1.4834990e-03 5.8424012e-03]\n",
      " [3.5838075e-03 4.7287720e-04 9.9594325e-01]\n",
      " [3.3437547e-03 9.9628347e-01 3.7276014e-04]\n",
      " [9.9632663e-01 5.4229936e-04 3.1310709e-03]\n",
      " [9.5873934e-01 2.7490340e-02 1.3770303e-02]]\n",
      "[[0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]]\n",
      "Evaluation for fold no-3:\n",
      "loss of 0.01032839622348547\n",
      "accuracy of 1.0\n",
      "--------------------------------------\n",
      "Training for fold no-4\n",
      "y_true: [2 2 0 1 0 1]\n",
      "y_pred: [2 2 0 1 0 1]\n",
      "[[1.6215039e-04 2.3677945e-04 9.9960107e-01]\n",
      " [3.3469016e-03 5.4266467e-04 9.9611050e-01]\n",
      " [9.9675035e-01 1.8938434e-03 1.3558123e-03]\n",
      " [1.9266820e-02 9.8007250e-01 6.6063757e-04]\n",
      " [9.9137735e-01 3.1560878e-03 5.4666051e-03]\n",
      " [2.2587916e-02 9.7593528e-01 1.4768075e-03]]\n",
      "[[0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]]\n",
      "Evaluation for fold no-4:\n",
      "loss of 0.010116471908986568\n",
      "accuracy of 1.0\n",
      "--------------------------------------\n",
      "Training for fold no-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dinova\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true: [2 2 2 1 2 1]\n",
      "y_pred: [2 2 2 1 2 1]\n",
      "[[0.01845538 0.00225833 0.97928625]\n",
      " [0.06101134 0.0049667  0.93402195]\n",
      " [0.01222113 0.00633691 0.9814419 ]\n",
      " [0.0767133  0.91384536 0.0094413 ]\n",
      " [0.01390475 0.00328634 0.9828089 ]\n",
      " [0.0472716  0.9358869  0.0168415 ]]\n",
      "[[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]]\n",
      "Evaluation for fold no-5:\n",
      "loss of 0.04693569615483284\n",
      "accuracy of 1.0\n",
      "--------------------------------------\n",
      "Best model is found to be fold no-4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dinova\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "Mean test accuracy of all folds are found to be: 100.0\n",
      "Mean test loss of all folds are found to be: 0.04129374995827675\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "2/2 [==============================] - 0s 18ms/step\n",
      "2/2 [==============================] - 0s 19ms/step\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "--------------------------------------\n",
      "ANN MODEL WITH Descale TRANSFORMATION\n",
      "--------------------------------------\n",
      "Training for fold no-1\n",
      "y_true: [0 2 2 1 2 2 1]\n",
      "y_pred: [0 2 2 1 2 2 1]\n",
      "[[0.5697682  0.25077784 0.17945392]\n",
      " [0.35316077 0.18969873 0.45714048]\n",
      " [0.2758492  0.1648886  0.5592622 ]\n",
      " [0.34437457 0.50716877 0.14845671]\n",
      " [0.2274515  0.18268652 0.589862  ]\n",
      " [0.3336617  0.18954086 0.4767975 ]\n",
      " [0.35230675 0.5042592  0.143434  ]]\n",
      "[[1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]]\n",
      "Evaluation for fold no-1:\n",
      "loss of 0.6512190103530884\n",
      "accuracy of 1.0\n",
      "--------------------------------------\n",
      "Training for fold no-2\n",
      "y_true: [1 0 1 0 0 2 2]\n",
      "y_pred: [1 0 1 0 0 2 2]\n",
      "[[0.2624346  0.49059102 0.24697444]\n",
      " [0.46596563 0.30196553 0.2320688 ]\n",
      " [0.2765979  0.46705836 0.25634378]\n",
      " [0.48112503 0.27886763 0.24000734]\n",
      " [0.41190675 0.3648438  0.22324951]\n",
      " [0.24374585 0.21542974 0.5408245 ]\n",
      " [0.3105745  0.21434467 0.4750809 ]]\n",
      "[[0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]]\n",
      "Evaluation for fold no-2:\n",
      "loss of 0.7449437379837036\n",
      "accuracy of 1.0\n",
      "--------------------------------------\n",
      "Training for fold no-3\n",
      "y_true: [0 2 0 0 2 1 0]\n",
      "y_pred: [0 2 0 0 2 1 0]\n",
      "[[0.43092233 0.33120012 0.23787758]\n",
      " [0.1765599  0.18647912 0.636961  ]\n",
      " [0.40678868 0.31782818 0.2753831 ]\n",
      " [0.4054549  0.35769752 0.2368476 ]\n",
      " [0.23433003 0.21919791 0.5464721 ]\n",
      " [0.2869892  0.53153914 0.18147175]\n",
      " [0.45722985 0.32292002 0.21985014]]\n",
      "[[1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]]\n",
      "Evaluation for fold no-3:\n",
      "loss of 0.7305573225021362\n",
      "accuracy of 1.0\n",
      "--------------------------------------\n",
      "Training for fold no-4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dinova\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true: [1 2 1 1 1 2]\n",
      "y_pred: [0 2 1 0 0 2]\n",
      "[[0.39932838 0.3602605  0.24041118]\n",
      " [0.3018544  0.18854202 0.5096035 ]\n",
      " [0.3174456  0.4066019  0.2759525 ]\n",
      " [0.46653125 0.31746536 0.21600337]\n",
      " [0.38922903 0.36031938 0.25045165]\n",
      " [0.30173224 0.194618   0.5036497 ]]\n",
      "[[0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]]\n",
      "Evaluation for fold no-4:\n",
      "loss of 0.9081661105155945\n",
      "accuracy of 0.5\n",
      "--------------------------------------\n",
      "Training for fold no-5\n",
      "y_true: [1 0 0 2 0 1]\n",
      "y_pred: [1 0 0 2 0 1]\n",
      "[[0.29098558 0.4834975  0.22551693]\n",
      " [0.46849096 0.25776836 0.27374065]\n",
      " [0.48727337 0.24550086 0.26722583]\n",
      " [0.21261527 0.17544131 0.6119434 ]\n",
      " [0.4504839  0.2873671  0.26214907]\n",
      " [0.28704292 0.49656296 0.21639416]]\n",
      "[[0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]]\n",
      "Evaluation for fold no-5:\n",
      "loss of 0.6987451910972595\n",
      "accuracy of 1.0\n",
      "--------------------------------------\n",
      "Best model is found to be fold no-1\n",
      "--------------------------------------\n",
      "Mean test accuracy of all folds are found to be: 90.0\n",
      "Mean test loss of all folds are found to be: 0.7467262744903564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dinova\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "--------------------------------------\n",
      "CNN MODEL WITH Descale TRANSFORMATION\n",
      "--------------------------------------\n",
      "Training for fold no-1\n",
      "y_true: [0 0 1 0 0 1 2]\n",
      "y_pred: [2 2 1 1 2 1 2]\n",
      "[[0.34341878 0.31037068 0.34621054]\n",
      " [0.3286856  0.3136926  0.3576218 ]\n",
      " [0.25036603 0.46498528 0.2846487 ]\n",
      " [0.31187382 0.34974077 0.33838537]\n",
      " [0.33593085 0.31399167 0.35007745]\n",
      " [0.2668502  0.4963749  0.23677482]\n",
      " [0.24718681 0.23244072 0.52037245]]\n",
      "[[1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]]\n",
      "Evaluation for fold no-1:\n",
      "loss of 0.9366926550865173\n",
      "accuracy of 0.4285714328289032\n",
      "--------------------------------------\n",
      "Training for fold no-2\n",
      "y_true: [2 2 1 0 0 2 1]\n",
      "y_pred: [2 2 1 0 0 2 1]\n",
      "[[0.2890913  0.13579816 0.5751106 ]\n",
      " [0.30122787 0.13638663 0.56238544]\n",
      " [0.30609825 0.5726773  0.12122441]\n",
      " [0.5212507  0.23527278 0.24347652]\n",
      " [0.52104574 0.26400352 0.21495074]\n",
      " [0.2278593  0.1307819  0.64135873]\n",
      " [0.2751629  0.563794   0.16104306]]\n",
      "[[0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]]\n",
      "Evaluation for fold no-2:\n",
      "loss of 0.5724096298217773\n",
      "accuracy of 1.0\n",
      "--------------------------------------\n",
      "Training for fold no-3\n",
      "y_true: [0 2 1 2 1 1 0]\n",
      "y_pred: [0 2 1 2 1 1 0]\n",
      "[[0.5232444  0.23979464 0.2369609 ]\n",
      " [0.28620917 0.13345855 0.5803322 ]\n",
      " [0.3060395  0.5834595  0.11050101]\n",
      " [0.25088304 0.09036909 0.65874785]\n",
      " [0.29904434 0.57675457 0.12420113]\n",
      " [0.2785504  0.61060536 0.1108443 ]\n",
      " [0.57878405 0.18954125 0.23167478]]\n",
      "[[1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]]\n",
      "Evaluation for fold no-3:\n",
      "loss of 0.5340749025344849\n",
      "accuracy of 1.0\n",
      "--------------------------------------\n",
      "Training for fold no-4\n",
      "y_true: [2 2 1 0 1 2]\n",
      "y_pred: [2 2 1 0 1 2]\n",
      "[[0.35356796 0.16843188 0.47800013]\n",
      " [0.35847807 0.15873407 0.4827878 ]\n",
      " [0.3552357  0.44793966 0.1968247 ]\n",
      " [0.5287458  0.26126304 0.20999117]\n",
      " [0.3524557  0.50266397 0.14488037]\n",
      " [0.24533305 0.13287188 0.6217951 ]]\n",
      "[[0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]]\n",
      "Evaluation for fold no-4:\n",
      "loss of 0.6782741546630859\n",
      "accuracy of 1.0\n",
      "--------------------------------------\n",
      "Training for fold no-5\n",
      "y_true: [0 1 2 1 0 2]\n",
      "y_pred: [0 1 2 1 0 2]\n",
      "[[0.43370834 0.30620936 0.26008233]\n",
      " [0.3312875  0.47348604 0.19522643]\n",
      " [0.26436213 0.21152657 0.52411133]\n",
      " [0.32442895 0.4564512  0.2191199 ]\n",
      " [0.44196197 0.2814312  0.27660683]\n",
      " [0.30729875 0.1926567  0.5000445 ]]\n",
      "[[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]]\n",
      "Evaluation for fold no-5:\n",
      "loss of 0.7538216710090637\n",
      "accuracy of 1.0\n",
      "--------------------------------------\n",
      "Best model is found to be fold no-3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dinova\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "Mean test accuracy of all folds are found to be: 88.57142865657806\n",
      "Mean test loss of all folds are found to be: 0.6950546026229858\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    }
   ],
   "source": [
    "# Commencing training for all colormapping and transformation combinations\n",
    "for transform in transformMethod:\n",
    "    for model in ModelMethod:\n",
    "        totalData, totalLabel, radioID = data_preprocess(transform)\n",
    "        preshuffled_data, preshuffled_label = preshuffle_data_label(totalData, totalLabel)\n",
    "        inputs_dims = (np.shape(preshuffled_data)[1], np.shape(preshuffled_data)[2], np.shape(preshuffled_data)[3])\n",
    "        rocPerFold, bestModelIndex, historyPerFold, modelPerFold, classRepPerFold = k_model_train(preshuffled_data, preshuffled_label, inputs_dims, transform, model, radioID)\n",
    "        save_roc_plot(transform, model, bestModelIndex, radioID, radioTokenizer, atomTokenizer, rocPerFold, evaluatePath)\n",
    "        save_learning_plot(transform, bestModelIndex, model, historyPerFold, evaluatePath)\n",
    "        save_accuracy_val(transform, bestModelIndex, model, historyPerFold, evaluatePath)\n",
    "        plot_accuracy_per_fold(transform, model, historyPerFold, evaluatePath)\n",
    "        plot_auc_per_fold(model, transform, rocPerFold, radioID, evaluatePath)\n",
    "        plot_classification_matrix_per_fold(model, transform, modelPerFold, preshuffled_data, preshuffled_label, evaluatePath)        \n",
    "        save_class_rep(model, transform, bestModelIndex, classRepPerFold, evaluatePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bestacc_for_model_transform(transform, bestModelIndex, model, historyPerFold, evaluatePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
